# PDF GPT Production Configuration (TOML)

[app]
name = "PDF GPT"
version = "1.0.0"
description = "Chat with Your PDF Documents"

[server]
OLLAMA_HOST = "http://localhost:11434"
OLLAMA_MODEL = "llama3"
FLASK_HOST = "0.0.0.0"
FLASK_PORT = 5000
FLASK_ENV = "production"
STREAMLIT_PORT = 8501

[storage]
UPLOAD_FOLDER = "data/uploads"
VECTOR_DB_PATH = "data/vector_db"
MAX_FILE_SIZE = 50  # MB
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

[security]
SECRET_KEY = "your-secret-key-change-this-in-production"
ALLOWED_HOSTS = ["localhost", "127.0.0.1", "0.0.0.0"]

[logging]
LOG_LEVEL = "INFO"
LOG_FILE = "logs/app.log"

[performance]
WORKERS = 4
THREADS = 2

[features]
ENABLE_RATE_LIMITING = true
ENABLE_CORS = true
MAX_UPLOADS_PER_HOUR = 10
ENABLE_METRICS = true

[ai]
DEFAULT_MODEL = "llama3"
AVAILABLE_MODELS = ["llama3", "gemma3"]
TEMPERATURE = 0.7
MAX_TOKENS = 1000

[database]
VECTOR_INDEX_TYPE = "faiss"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
SIMILARITY_THRESHOLD = 0.1
